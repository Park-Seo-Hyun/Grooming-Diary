import torch
import torch.nn.functional as F
import os
from typing import Dict, Any

# âš ï¸ ìˆ˜ì •: íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì˜ weightsê°€ ì €ì¥ëœ ë¡œì»¬ ê²½ë¡œ
FINE_TUNED_MODEL_PATH = r"D:/Grooming/backend/app/ai_model/fine_tuned_kobert_nlp" 
# NOTE: ì‹¤ì œ ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìœ„ì˜ ê²½ë¡œë¥¼ 'FINE_TUNED_MODEL_PATH' ë³€ìˆ˜ì— ì •í™•íˆ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.

# ğŸŒŸ íŒŒì¸íŠœë‹ ì‹œ ì‚¬ìš©í•œ ë ˆì´ë¸” ìˆœì„œì™€ ë™ì¼í•˜ê²Œ ë§¤í•‘ (ë§¤ìš° ì¤‘ìš”)
# finetune_kobert.py: EMOTION_LABELS_MAP = {"Angry": 0, "Fear": 1, "Happy": 2, "Tender": 3, "Sad": 4}
EMOTION_LABELS = {
    0: ("Angry", "angry.png"),   # ID 0
    1: ("Fear", "fear.png"),     # ID 1
    2: ("Happy", "happy.png"),   # ID 2
    3: ("Tender", "tender.png"), # ID 3
    4: ("Sad", "sad.png")        # ID 4
}

# -------------------------- ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ --------------------------
# ëª¨ë¸ ë¡œë”©ì„ ìœ„í•œ Dynamic Import (transformersëŠ” ëª¨ë¸ íƒ€ì…ì„ ìë™ìœ¼ë¡œ ì¶”ë¡ )
try:
    from transformers import AutoTokenizer, AutoModelForSequenceClassification 
    
    # ğŸŒŸ FIX 1: í† í¬ë‚˜ì´ì €ëŠ” ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ KoBERTì˜ ì˜¤ë¦¬ì§€ë„ ì†ŒìŠ¤ ('monologg/kobert')ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.
    # í† í¬ë‚˜ì´ì €ì˜ ì„¤ì • íŒŒì¼ ëˆ„ë½ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.
    tokenizer = AutoTokenizer.from_pretrained('monologg/kobert', trust_remote_code=True)
    
    # ëª¨ë¸ ë¡œë“œ (GPUê°€ ìˆë‹¤ë©´ GPU, ì—†ë‹¤ë©´ CPU)
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # ğŸŒŸ FIX 2: ëª¨ë¸ weightsëŠ” ë¡œì»¬ ê²½ë¡œì—ì„œ íŒŒì¸íŠœë‹ëœ ë²„ì „ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    model = AutoModelForSequenceClassification.from_pretrained(FINE_TUNED_MODEL_PATH, trust_remote_code=True).to(DEVICE)
    model.eval() # ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •
    
    print(f"INFO: Fine-tuned NLP model loaded successfully from {FINE_TUNED_MODEL_PATH} on {DEVICE}.")
    LOAD_SUCCESS = True
except ImportError:
    print(f"ERROR: 'transformers' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    LOAD_SUCCESS = False
except OSError as e:
    # âš ï¸ ì´ì œ OSErrorëŠ” ê²½ë¡œ ë¬¸ì œ ë˜ëŠ” íŒŒì¼ ëˆ„ë½ ë¬¸ì œì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
    print(f"ERROR: Failed to load NLP model from {FINE_TUNED_MODEL_PATH}. ê²½ë¡œ ë° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í•„ìš”. ìƒì„¸ ì˜¤ë¥˜: {e}")
    LOAD_SUCCESS = False
except Exception as e:
    print(f"ERROR: Failed to load NLP model: {e}")
    LOAD_SUCCESS = False

# ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ì‹œ ë”ë¯¸ í•¨ìˆ˜ë¡œ ëŒ€ì²´
if not LOAD_SUCCESS:
    def tokenizer(text, **kwargs): return {'input_ids': torch.tensor([[101, 102]]), 'attention_mask': torch.tensor([[1, 1]])}
    
    class DummyModel:
        def __call__(self, **kwargs):
            # 5ê°œ ë ˆì´ë¸”ì— ëŒ€í•œ ë”ë¯¸ ë¡œì§“ ë°˜í™˜ (Happyë¡œ ê°€ì •)
            return type('Outputs', (object,), {'logits': torch.tensor([[0.1, 0.1, 10.0, 0.1, 0.1]])})
        def to(self, device): return self
        def eval(self): pass
        
    model = DummyModel()
    DEVICE = "cpu"
# ---------------------------------------------------------------------


def get_emotion_analysis(text: str) -> dict:
    """
    ì‚¬ìš©ìì˜ ì¼ê¸° í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ê°ì • ë ˆì´ë¸”, ì ìˆ˜, ì´ëª¨ì§€ íŒŒì¼ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not text or not LOAD_SUCCESS:
        # ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ë˜ëŠ” í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆì„ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
        return {
            "emotion_label": "Neutral",
            "emotion_emoji": "default.png",
            "emotion_score": 0.0,
            "overall_emotion_score": {label[0]: 0.0 for label in EMOTION_LABELS.values()}
        }
        
    # í…ìŠ¤íŠ¸ í† í°í™”
    inputs = tokenizer(
        text, 
        return_tensors='pt', 
        padding=True, 
        truncation=True,
        max_length=128 # í•™ìŠµ ì‹œ ì‚¬ìš©í•œ MAX_LENGTHì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
    ).to(DEVICE)
    
    # ëª¨ë¸ ì¶”ë¡ 
    with torch.no_grad():
        outputs = model(**inputs)
        
    ## í™•ë¥  ê³„ì‚° (Softmax ì ìš©)
    # probabilities: ëª¨ë“  ê°ì • ë ˆì´ë¸”ì˜ í™•ë¥  ë¦¬ìŠ¤íŠ¸ 
    probabilities = F.softmax(outputs.logits, dim=1).squeeze().tolist()
    
    # ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ ê°ì •ì˜ ì¸ë±ìŠ¤ ì¶”ì¶œ
    predicted_label_index = torch.argmax(outputs.logits, dim=1).item()
    
    # ê²°ê³¼ ë§¤í•‘
    emotion_score = probabilities[predicted_label_index]
    emotion_label = EMOTION_LABELS[predicted_label_index][0]
    emotion_emoji = EMOTION_LABELS[predicted_label_index][1]
    
    overall_emotion_score: Dict[str, float] = {}
    
    # ì „ì²´ ê°ì • ì ìˆ˜ ë§¤í•‘ (íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì˜ ì¶œë ¥ ìˆœì„œì— ë”°ë¼)
    for i, (label, _) in EMOTION_LABELS.items():
        # probabilities ë¦¬ìŠ¤íŠ¸ê°€ EMOTION_LABELSì˜ ì¸ë±ìŠ¤ ìˆœì„œ(0, 1, 2, 3, 4)ì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
        if i < len(probabilities):
            overall_emotion_score[label] = probabilities[i]
    
    return {
        "emotion_label": emotion_label,
        "emotion_emoji": emotion_emoji,
        "emotion_score": emotion_score,
        "overall_emotion_score": overall_emotion_score
    }